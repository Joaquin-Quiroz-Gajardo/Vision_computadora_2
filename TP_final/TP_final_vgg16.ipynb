{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP_final_vgg16.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpGNRt7VRia6",
        "outputId": "d0c2c68d-fca3-407d-cb51-21a37b0a0bf4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yMuHTw9VRGDE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e2a5d0e-65ea-4ea1-802b-4a98a2c809e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 785)\n",
            "Index(['label', 'pixel0', 'pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5',\n",
            "       'pixel6', 'pixel7', 'pixel8',\n",
            "       ...\n",
            "       'pixel774', 'pixel775', 'pixel776', 'pixel777', 'pixel778', 'pixel779',\n",
            "       'pixel780', 'pixel781', 'pixel782', 'pixel783'],\n",
            "      dtype='object', length=785)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['pixel0', 'pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5', 'pixel6',\n",
            "       'pixel7', 'pixel8', 'pixel9',\n",
            "       ...\n",
            "       'pixel774', 'pixel775', 'pixel776', 'pixel777', 'pixel778', 'pixel779',\n",
            "       'pixel780', 'pixel781', 'pixel782', 'pixel783'],\n",
            "      dtype='object', length=784)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df_train=pd.read_csv(\"/content/drive/MyDrive/uba/vision 2/train.csv\")\n",
        "print(df_train.shape)\n",
        "print(df_train.columns)\n",
        "\n",
        "train_label = np.array(df_train[\"label\"])\n",
        "df_train.drop(\"label\", 1, inplace=True)\n",
        "print(df_train.columns)\n",
        "\n",
        "train_images=np.zeros((len(df_train), 1, 28, 28))\n",
        "for index, row in df_train.iterrows():\n",
        "    fila=0\n",
        "    columna=0\n",
        "    for i in range(784):\n",
        "        # print(row[\"pixel\"+str(i)])\n",
        "        columna +=1\n",
        "        if (i+1)%28 == 0 and i<782:\n",
        "            fila+=1\n",
        "            columna=0\n",
        "            # print((i+1)/28)\n",
        "        elif i>782:\n",
        "            columna-=1\n",
        "        # print(columna)\n",
        "        train_images[index, 0, fila, columna] = row[\"pixel\"+str(i)]\n",
        "    # print(train_images[index,0])\n",
        "    # break\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_images/255, train_label, test_size=0.2, random_state=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import dataloader\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "torch.manual_seed(0)\n",
        "\n",
        "train_dataset = TensorDataset(torch.tensor(X_train),torch.tensor(y_train)) # create your datset\n",
        "train_dataset.transform = transforms.Compose([\n",
        "                transforms.transforms.GaussianBlur(3,1.2),\n",
        "                transforms.RandomAdjustSharpness(0.8,0.2),\n",
        "                transforms.RandomAutocontrast(0.2),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.1307,), (0.3081,))\n",
        "            ])\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=0) # create your dataloader\n",
        "\n",
        "test_dataset = TensorDataset(torch.tensor(X_test),torch.tensor(y_test)) # create your datset\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=True, num_workers=0) # create your dataloader"
      ],
      "metadata": {
        "id": "P6BviQcrnwD0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "class Identity(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Identity, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x\n",
        "\n",
        "vgg = models.vgg16(pretrained=True)\n",
        "vgg.features[0]=nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(5, 5))\n",
        "# resnet18.avgpool = Identity()\n",
        "vgg.classifier[6]=nn.Linear(in_features=4096, out_features=10, bias=True)\n",
        "vgg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgIqP3m9x9y6",
        "outputId": "50ddb10f-3547-4665-b92b-61ea0a5e92e2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(5, 5))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = vgg\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(5):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_dataloader):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs.float())\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 200 == 199:    # print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 200:.3f}')\n",
        "            running_loss = 0.0\n"
      ],
      "metadata": {
        "id": "HWntORL6yGg6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in test_dataloader:\n",
        "        images, labels = data\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = model(images.float())\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {100 * correct / total}%')"
      ],
      "metadata": {
        "id": "y_zfbxixHgNP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "471c6566-4b87-4381-f9e5-477107fae773"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 99.025%\n"
          ]
        }
      ]
    }
  ]
}